# -*- coding: utf-8 -*-
"""dataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15lyXSu06z14MKsLJS0LZmEVRnh7U5Hrz
"""

import os
import pandas as pd
import torch
from torch.utils.data import Dataset, DataLoader
import re

class VQGTensorDataset(Dataset):
    def __init__(self, csv_path, vocab, max_length=20, base_dir=""):
        self.df = pd.read_csv(csv_path)
        self.vocab = vocab
        self.max_length = max_length
        self.base_dir = base_dir

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        tensor_path = os.path.join(self.base_dir, row["tensor_path"])
        image_tensor = torch.load(tensor_path).float()
        
        question = str(row["questions"]).lower()
        tokens = re.findall(r"\w+|[^\w\s]", question, re.UNICODE)

        indices = [self.vocab.get(token, self.vocab['<unk>']) for token in tokens]
        indices = [self.vocab['<start>']] + indices + [self.vocab['<end>']]
        indices = indices[:self.max_length] + [self.vocab['<pad>']] * (self.max_length - len(indices))
        
        return image_tensor, torch.tensor(indices), question


def load_csv_paths(base_dir):
    """
    Recursively load CSV paths for train/val/test splits under 'bing' and 'flickr'.
    """
    csvs = {"bing": {}, "flickr": {}}

    for root, _, files in os.walk(base_dir):
        for fname in files:
            if not fname.endswith(".csv"):
                continue
            fpath = os.path.join(root, fname)
            if fname.startswith("bing_"):
                if "train" in fname:
                    csvs["bing"]["train"] = fpath
                elif "val" in fname:
                    csvs["bing"]["val"] = fpath
                elif "test" in fname:
                    csvs["bing"]["test"] = fpath
            elif fname.startswith("flickr_"):
                if "train" in fname:
                    csvs["flickr"]["train"] = fpath
                elif "val" in fname:
                    csvs["flickr"]["val"] = fpath
                elif "test" in fname:
                    csvs["flickr"]["test"] = fpath

    return csvs



def create_dataloaders(dataset_paths, vocab, batch_size, max_length):
    loaders = {}
    for domain, splits in dataset_paths.items():
        loaders[domain] = {}
        for split, path in splits.items():
            dataset = VQGTensorDataset(path, vocab, max_length)
            loaders[domain][split] = DataLoader(dataset, batch_size=batch_size, shuffle=(split == "train"))
    return loaders