# -*- coding: utf-8 -*-
"""train.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15lyXSu06z14MKsLJS0LZmEVRnh7U5Hrz
"""

import torch
from tqdm import tqdm
import matplotlib.pyplot as plt

def train_model(model, train_loader, val_loader, vocab, criterion, optimizer, device, epochs):
    history = {"train_loss": [], "val_loss": []}
    for epoch in range(epochs):
        model.train()
        total_loss = 0
        for imgs, caps, _ in tqdm(train_loader, desc=f"Epoch {epoch+1}"):
            imgs, caps = imgs.to(device), caps.to(device)
            out = model(imgs, caps)
            loss = criterion(out.view(-1, len(vocab)), caps.view(-1))
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        history["train_loss"].append(total_loss / len(train_loader))

        # validation
        model.eval()
        val_loss = 0
        with torch.no_grad():
            for imgs, caps, _ in val_loader:
                imgs, caps = imgs.to(device), caps.to(device)
                out = model(imgs, caps)
                loss = criterion(out.view(-1, len(vocab)), caps.view(-1))
                val_loss += loss.item()
        history["val_loss"].append(val_loss / len(val_loader))
    return history

def plot_history(history):
    plt.plot(history["train_loss"], label="Train")
    plt.plot(history["val_loss"], label="Val")
    plt.legend()
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.title("Training History")
    plt.show()